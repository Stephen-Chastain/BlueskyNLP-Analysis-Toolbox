{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1aa677eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import re\n",
    "import snowflake.connector\n",
    "from snowflake.connector.pandas_tools import write_pandas\n",
    "from time import sleep\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "### GLOBAL VARS | GLOBAL VARS | GLOBAL VARS | GLOBAL VARS | GLOBAL VARS | GLOBAL VARS | GLOBAL VARS | GLOBAL VARS | GLOBAL VARS | GLOBAL VARS | GLOBAL VARS \n",
    "### GLOBAL VARS | GLOBAL VARS | GLOBAL VARS | GLOBAL VARS | GLOBAL VARS | GLOBAL VARS | GLOBAL VARS | GLOBAL VARS | GLOBAL VARS | GLOBAL VARS | GLOBAL VARS \n",
    "### GLOBAL VARS | GLOBAL VARS | GLOBAL VARS | GLOBAL VARS | GLOBAL VARS | GLOBAL VARS | GLOBAL VARS | GLOBAL VARS | GLOBAL VARS | GLOBAL VARS | GLOBAL VARS \n",
    "\n",
    "# this basically means \"smoke em if you got em\" where the \"em\" is NVIDIA GPU\n",
    "DEVICE = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "SF_USR = os.getenv('SF_USR')\n",
    "SF_ID  = os.getenv('SF_ID')\n",
    "SF_WH  = os.getenv('SF_WH')\n",
    "SF_DB  = os.getenv('SF_DB')\n",
    "SF_SC  = os.getenv('SF_SC')\n",
    "SF_RL  = os.getenv('SF_RL')\n",
    "\n",
    "# connect to database and init a cursor for querying\n",
    "xct_params = {\n",
    "    \"user\":                 SF_USR\n",
    "   ,\"account\":              SF_ID\n",
    "   ,\"warehouse\":            SF_WH\n",
    "   ,\"database\":             SF_DB\n",
    "   ,\"schema\":               SF_SC\n",
    "   ,\"role\":                 SF_RL\n",
    "   ,\"private_key_file\":     os.getenv('PRIVATE_KEY_PATH')\n",
    "   ,\"private_key_file_pwd\": os.getenv('PRIVATE_KEY_PASSPHRASE')\n",
    "   ,\"authenticator\":        os.getenv('SF_AUTH')\n",
    "}\n",
    "\n",
    "SF_XCT = snowflake.connector.connect(**xct_params) #connection object\n",
    "CSR = SF_XCT.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a44ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"select * from {SF_DB}.{SF_SC}.threads_keywords_summarystats\"\"\" \n",
    "CSR.execute(query)\n",
    "threadsdf = CSR.fetch_pandas_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3c39b6",
   "metadata": {},
   "source": [
    "With NLP posts grouped as threads to minimize pseudoreplication, we could calculate confidence intervals for positive, negative, and neutral sentiment simultaneously. The Sison and Glaz method is designed for a multinomial proportion like this with more than 2 possible outcomes but may not be the best option here.\n",
    "\n",
    "Chi Squares Goodness-of-fit test\n",
    "\n",
    "For now, we assume that the null hypothesis-- which would represent a hypothetical social media platform with no political leaning-- is a 33/33/33% split between the three sentiment categories. In the future I hope to integrate real poll data to track approval ratings of keywords. \n",
    "\n",
    "In the future we can also add in translations from other languages in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2618d9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##--Chi Squares Test\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2\n",
    "\n",
    "ALPHA = 0.05\n",
    "DEGREES_OF_FREEDOM = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343b6ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [KEYWORD, TOPIC, CATEGORY, TOTAL_AUTHORS, TOTAL_THREADS, TOTAL_POSTS, TOTAL_POSITIVE_POSTS, TOTAL_NEUTRAL_POSTS, TOTAL_NEGATIVE_POSTS, POSITIVE_THREADS, NEUTRAL_THREADS, NEGATIVE_THREADS, PERCENT_POSITIVE, PERCENT_NEUTRAL, PERCENT_NEGATIVE, AVG_SENTIMENT_CONFIDENCE, EXPECTED_THREADS_PER_SENTIMENT, CHI_SQUARED_STATISTIC, P_VALUE, SIGNIFICANTLY_DIFFERENT_FROM_EVEN_SPLIT]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#hypothetical perfectly even sentiment split\n",
    "threadsdf['EXPECTED_THREADS_PER_SENTIMENT'] = threadsdf['TOTAL_THREADS'] / 3\n",
    "\n",
    "CHI_SQUARED_POSITIVE = ((threadsdf['POSITIVE_THREADS'] - threadsdf['EXPECTED_THREADS_PER_SENTIMENT'])**2) / threadsdf['EXPECTED_THREADS_PER_SENTIMENT']\n",
    "CHI_SQUARED_NEUTRAL = ((threadsdf['NEUTRAL_THREADS'] - threadsdf['EXPECTED_THREADS_PER_SENTIMENT'])**2) / threadsdf['EXPECTED_THREADS_PER_SENTIMENT']\n",
    "CHI_SQUARED_NEGATIVE = ((threadsdf['NEGATIVE_THREADS'] - threadsdf['EXPECTED_THREADS_PER_SENTIMENT'])**2) / threadsdf['EXPECTED_THREADS_PER_SENTIMENT']\n",
    "\n",
    "threadsdf['CHI_SQUARED_STATISTIC'] = CHI_SQUARED_POSITIVE + CHI_SQUARED_NEUTRAL + CHI_SQUARED_NEGATIVE\n",
    "\n",
    "threadsdf['P_VALUE'] = chi2.sf(threadsdf['CHI_SQUARED_STATISTIC'], DEGREES_OF_FREEDOM)\n",
    "\n",
    "threadsdf['SIGNIFICANTLY_DIFFERENT_FROM_EVEN_SPLIT'] = threadsdf['P_VALUE'] < ALPHA\n",
    "print(threadsdf)\n",
    "\n",
    "not_significantly_different = threadsdf[~threadsdf['SIGNIFICANTLY_DIFFERENT_FROM_EVEN_SPLIT']].copy()\n",
    "print(not_significantly_different)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
